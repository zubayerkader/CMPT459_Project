import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn import preprocessing
from sklearn.pipeline import Pipeline
from sklearn.compose import make_column_transformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
import datetime as dt
from tune_params import *
import pickle

def Knn_preprocess(df):
    df = df.loc[:, df.columns != 'province']
    df = df.loc[:, df.columns != 'country']
    # print(df)

    df_2 = df.loc[:, df.columns == 'sex']
    # print (df_2)
    enc = preprocessing.OneHotEncoder()
    enc.fit(df_2)
    onehotlabels = enc.transform(df_2).toarray()
    # print (onehotlabels)
    df['female'] = onehotlabels[:, 0]
    df['male'] = onehotlabels[:, 1]
    # print (df)
    df = df.loc[:, df.columns != 'sex']
    X = df.loc[:, df.columns != 'outcome']
    y = df['outcome']

    # from sklearn.preprocessing import StandardScaler
    # std_scaler = StandardScaler()
    # X = pd.DataFrame(std_scaler.fit_transform(X), columns=X.columns)

    min_max_scaler = preprocessing.MinMaxScaler()
    X = pd.DataFrame(min_max_scaler.fit_transform(X), columns=X.columns)

    X['outcome'] = y
    # print (X)

    return X


def Random_forest_preprocess(df):
    le = preprocessing.LabelEncoder()
    string_cols = ['sex','province','country','outcome']
    for col in string_cols:
        df[col] = le.fit_transform(df[col])
    # print(df)
    return df
    # remember there is a le.inverse_transform(y) to get back the string outcome

def Ada_Boosting_preprocess(df):
    le = preprocessing.LabelEncoder()
    string_cols = ['sex','province','country','outcome']
    for col in string_cols:
        df[col] = le.fit_transform(df[col])

    return df
    # remember there is a le.inverse_transform(y) to get back the string outcome

def main():
    df = pd.read_csv("../data/cases_train_processed.csv")
    df['date_confirmation'] = pd.to_datetime(df['date_confirmation'])
    df['date_confirmation'] =((df['date_confirmation'] - dt.datetime(2020,1,1)).dt.total_seconds())/(3600)
    # print (df)

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("KNN hyperparameter tuning in progress: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # tuning parameters
    knn_data = Knn_preprocess(df)
    params = {
    	"n_neighbors": 1,
    	"n_neighbors_increment": 1,
    }
    tune_params(knn_data, params, loops=20, model_name="KNeighborsClassifier")

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("Creating model using best parameters and saving to pkl: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # creating model using best parameters and saving to pkl
    # k=7 from plot generated by tune_params
    X = knn_data.loc[:, knn_data.columns != 'outcome']
    y = knn_data['outcome']
    model = KNeighborsClassifier(n_neighbors=7, weights = 'distance')
    model.fit(X,y)

    pkl_filename = "../models/KNeighborsClassifier.pkl"
    with open(pkl_filename, 'wb') as file:
        pickle.dump(model, file)

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("testing model using saved pkl: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # test pkl
    with open(pkl_filename, 'rb') as file:
        pickle_model = pickle.load(file)

    sample = knn_data.sample(frac=0.2)
    Xtest = sample.loc[:, sample.columns != 'outcome']
    Ytest = sample['outcome']
    score = pickle_model.score(Xtest, Ytest)
    print("KNeighborsClassifier Test score on training data: {0:.2f} %".format(100 * score))
#####################################################################################################################

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("Random forest hyperparameter tuning in progress: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    rf_data = Random_forest_preprocess(df)
    params = {
    	"n_estimators": 20,
    	"max_depth": 3,
        "n_estimators_increment":0,
        "max_depth_increment":1
    }
    tune_params(rf_data, params, loops=30, model_name="RandomForestClassifier")

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("Creating model using best parameters and saving to pkl: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # creating model using best parameters and saving to pkl
    # n_estimators=20, max_depth=19 from plot generated by tune_params
    X = rf_data.loc[:, rf_data.columns != 'outcome']
    y = rf_data['outcome']
    model = RandomForestClassifier(n_estimators=20, max_depth=19)
    model.fit(X,y)

    pkl_filename = "../models/RandomForestClassifier.pkl"
    with open(pkl_filename, 'wb') as file:
        pickle.dump(model, file)

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("testing model using saved pkl: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # test pkl
    with open(pkl_filename, 'rb') as file:
        pickle_model = pickle.load(file)

    sample = rf_data.sample(frac=0.2)
    Xtest = sample.loc[:, sample.columns != 'outcome']
    Ytest = sample['outcome']
    score = pickle_model.score(Xtest, Ytest)
    print("RandomForestClassifier Test score on training data: {0:.2f} %".format(100 * score))
#####################################################################################################################

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("AdaBoost hyperparameter tuning in progress: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    ada_data = Ada_Boosting_preprocess(df)
    params = {
    	# "n_estimators": 1,
        "max_depth": 2,
        "max_depth_increment": 1,
        # "n_estimators_increment": 1,
    }
    tune_params(ada_data, params, loops=30, model_name="AdaBoostClassifier")

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("Creating model using best parameters and saving to pkl: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # n_estimators=20 from plot generated by tune_params
    X = ada_data.loc[:, ada_data.columns != 'outcome']
    y = ada_data['outcome']
    base = DecisionTreeClassifier(max_depth=16)
    model = AdaBoostClassifier(base_estimator=base)
    model.fit(X,y)

    pkl_filename = "../models/AdaBoostClassifier.pkl"
    with open(pkl_filename, 'wb') as file:
        pickle.dump(model, file)

    print ("\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")
    print ("testing model using saved pkl: ")
    print ("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n")
    # test pkl
    with open(pkl_filename, 'rb') as file:
        pickle_model = pickle.load(file)

    sample = ada_data.sample(frac=0.2)
    Xtest = sample.loc[:, sample.columns != 'outcome']
    Ytest = sample['outcome']
    score = pickle_model.score(Xtest, Ytest)
    print("AdaBoostClassifier Test score on training data: {0:.2f} %".format(100 * score))


if __name__ == '__main__':
    main()
